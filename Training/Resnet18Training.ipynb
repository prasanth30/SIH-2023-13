{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport albumentations as A\nfrom PIL import Image\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-27T14:20:33.495910Z","iopub.execute_input":"2023-09-27T14:20:33.496408Z","iopub.status.idle":"2023-09-27T14:20:33.504870Z","shell.execute_reply.started":"2023-09-27T14:20:33.496372Z","shell.execute_reply":"2023-09-27T14:20:33.503014Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"fol = np.sort(os.listdir('/kaggle/input/dermnet/train'))\nfol\ndic ={}\nfor i,x in enumerate(fol):\n    dic[x]=i\ndic\n#ID La","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:20:33.507400Z","iopub.execute_input":"2023-09-27T14:20:33.508259Z","iopub.status.idle":"2023-09-27T14:20:33.528118Z","shell.execute_reply.started":"2023-09-27T14:20:33.508126Z","shell.execute_reply":"2023-09-27T14:20:33.527105Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"{'Acne and Rosacea Photos': 0,\n 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 1,\n 'Atopic Dermatitis Photos': 2,\n 'Bullous Disease Photos': 3,\n 'Cellulitis Impetigo and other Bacterial Infections': 4,\n 'Eczema Photos': 5,\n 'Exanthems and Drug Eruptions': 6,\n 'Hair Loss Photos Alopecia and other Hair Diseases': 7,\n 'Herpes HPV and other STDs Photos': 8,\n 'Light Diseases and Disorders of Pigmentation': 9,\n 'Lupus and other Connective Tissue diseases': 10,\n 'Melanoma Skin Cancer Nevi and Moles': 11,\n 'Nail Fungus and other Nail Disease': 12,\n 'Poison Ivy Photos and other Contact Dermatitis': 13,\n 'Psoriasis pictures Lichen Planus and related diseases': 14,\n 'Scabies Lyme Disease and other Infestations and Bites': 15,\n 'Seborrheic Keratoses and other Benign Tumors': 16,\n 'Systemic Disease': 17,\n 'Tinea Ringworm Candidiasis and other Fungal Infections': 18,\n 'Urticaria Hives': 19,\n 'Vascular Tumors': 20,\n 'Vasculitis Photos': 21,\n 'Warts Molluscum and other Viral Infections': 22}"},"metadata":{}}]},{"cell_type":"code","source":"dftrain = pd.DataFrame(columns=['id','label','y'])\n\nfor folder in fol:\n    ls = os.listdir('/kaggle/input/dermnet/train/'+folder)\n    for x in ls:\n        #print(folder)\n        dftrain.loc[len(dftrain)] = {'id':x,'label':folder,'y':dic[folder]}\ndftrain","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:20:33.529894Z","iopub.execute_input":"2023-09-27T14:20:33.530853Z","iopub.status.idle":"2023-09-27T14:21:02.686695Z","shell.execute_reply.started":"2023-09-27T14:20:33.530812Z","shell.execute_reply":"2023-09-27T14:21:02.685815Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                  id  \\\n0                       milia-11.jpg   \n1                acne-cystic-102.jpg   \n2               acne-infantile-2.jpg   \n3                acne-cystic-146.jpg   \n4                  acne-cystic-6.jpg   \n...                              ...   \n15552            warts-common-55.jpg   \n15553                   warts-40.jpg   \n15554       warts-cryotherapy-17.jpg   \n15555  molluscum-contagiosum-124.jpg   \n15556          warts-digitate-62.jpg   \n\n                                            label   y  \n0                         Acne and Rosacea Photos   0  \n1                         Acne and Rosacea Photos   0  \n2                         Acne and Rosacea Photos   0  \n3                         Acne and Rosacea Photos   0  \n4                         Acne and Rosacea Photos   0  \n...                                           ...  ..  \n15552  Warts Molluscum and other Viral Infections  22  \n15553  Warts Molluscum and other Viral Infections  22  \n15554  Warts Molluscum and other Viral Infections  22  \n15555  Warts Molluscum and other Viral Infections  22  \n15556  Warts Molluscum and other Viral Infections  22  \n\n[15557 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>milia-11.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>acne-cystic-102.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>acne-infantile-2.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>acne-cystic-146.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>acne-cystic-6.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15552</th>\n      <td>warts-common-55.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>15553</th>\n      <td>warts-40.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>15554</th>\n      <td>warts-cryotherapy-17.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>15555</th>\n      <td>molluscum-contagiosum-124.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>15556</th>\n      <td>warts-digitate-62.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n<p>15557 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:02.688428Z","iopub.execute_input":"2023-09-27T14:21:02.689521Z","iopub.status.idle":"2023-09-27T14:21:02.694973Z","shell.execute_reply.started":"2023-09-27T14:21:02.689472Z","shell.execute_reply":"2023-09-27T14:21:02.693506Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"dftest = pd.DataFrame(columns=['id','label','y'])\n\nfor folder in fol:\n    ls = os.listdir('/kaggle/input/dermnet/test/'+folder)\n    for x in ls:\n        #print(folder)\n        dftest.loc[len(dftest)] = {'id':x,'label':folder,'y':dic[folder]}\ndftest","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:02.697209Z","iopub.execute_input":"2023-09-27T14:21:02.697799Z","iopub.status.idle":"2023-09-27T14:21:08.951519Z","shell.execute_reply.started":"2023-09-27T14:21:02.697751Z","shell.execute_reply":"2023-09-27T14:21:08.950369Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                                   id  \\\n0                   acne-cystic-6.jpg   \n1     hidradenitis-suppurativa-43.jpg   \n2             acne-open-comedo-67.jpg   \n3          perioral-dermatitis-10.jpg   \n4                 hyperhidrosis-2.jpg   \n...                               ...   \n3997              warts-common-96.jpg   \n3998            herpes-simplex-37.jpg   \n3999            herpes-zoster-182.jpg   \n4000    molluscum-contagiosum-155.jpg   \n4001                warts-flat-20.jpg   \n\n                                           label   y  \n0                        Acne and Rosacea Photos   0  \n1                        Acne and Rosacea Photos   0  \n2                        Acne and Rosacea Photos   0  \n3                        Acne and Rosacea Photos   0  \n4                        Acne and Rosacea Photos   0  \n...                                          ...  ..  \n3997  Warts Molluscum and other Viral Infections  22  \n3998  Warts Molluscum and other Viral Infections  22  \n3999  Warts Molluscum and other Viral Infections  22  \n4000  Warts Molluscum and other Viral Infections  22  \n4001  Warts Molluscum and other Viral Infections  22  \n\n[4002 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>acne-cystic-6.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hidradenitis-suppurativa-43.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>acne-open-comedo-67.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>perioral-dermatitis-10.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hyperhidrosis-2.jpg</td>\n      <td>Acne and Rosacea Photos</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>warts-common-96.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>herpes-simplex-37.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>herpes-zoster-182.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4000</th>\n      <td>molluscum-contagiosum-155.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4001</th>\n      <td>warts-flat-20.jpg</td>\n      <td>Warts Molluscum and other Viral Infections</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n<p>4002 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\n# given:\n# features: xs\n# ground truth: ys\n\nx_train, x_val, y_train, y_val = train_test_split(dftrain['id'], dftrain['y'],\n                                                    test_size=0.33,\n                                                    random_state=0,\n                                                    stratify=dftrain['y'])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:08.956272Z","iopub.execute_input":"2023-09-27T14:21:08.956716Z","iopub.status.idle":"2023-09-27T14:21:08.976442Z","shell.execute_reply.started":"2023-09-27T14:21:08.956682Z","shell.execute_reply":"2023-09-27T14:21:08.975111Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n#         A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        A.CenterCrop(height=300, width=300),\n                \n        A.HorizontalFlip(p=0.3),\n        A.VerticalFlip(p=0.3),\n#         A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        A.RandomBrightnessContrast(p=0.5),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n#         FiveCrop(405), # this is a list of PIL Images\n#         Lambda(lambda crops: torch.stack([PILToTensor()(crop) for crop in crops])),\n        ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:08.978547Z","iopub.execute_input":"2023-09-27T14:21:08.978970Z","iopub.status.idle":"2023-09-27T14:21:08.988066Z","shell.execute_reply.started":"2023-09-27T14:21:08.978936Z","shell.execute_reply":"2023-09-27T14:21:08.986563Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self,folder,train='True',test=True):\n        self.train=train\n        self.folder = folder\n        self.lis = np.sort(os.listdir(folder))\n        self.transform = transform\n        self.test=test\n    def gammaCorrection(self,src, gamma=2.5):\n        cv2_image = np.transpose(src, (1, 2, 0))\n        cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)\n        invGamma = 1.0/2.5\n\n        table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n        table = np.array(table, np.uint8)\n        ret['x'] =cv.LUT(src, table) \n        return ret\n    def __len__(self):\n        if self.train==True:\n            return x_train.shape[0]\n        elif self.test==False:\n            return x_val.shape[0]\n        else:\n            return dftest.shape[0]\n    \n    def __getitem__(self,idx):\n        if self.train==True:\n            file_path = '/kaggle/input/dermnet/train/'+fol[y_train.iloc[idx]]+'/'+x_train.iloc[idx]\n            y=y_train.iloc[idx]\n        elif self.train==False and self.test==False:\n            file_path = '/kaggle/input/dermnet/train/'+fol[y_val.iloc[idx]]+'/'+x_val.iloc[idx]\n            y = y_val.iloc[idx]\n        else:\n            file_path = '/kaggle/input/dermnet/test/'+dftest['label'].iloc[idx]+'/'+dftest['id'].iloc[idx]\n            y = dftest['y'].iloc[idx]\n        \n#         else:\n#             y = torch.tensor(1)\n#             file_path = self.folder+'/'+self.lis[1]+'/'+np.sort(os.listdir(self.folder+'/'+self.lis[1]))[idx-len(os.listdir(self.folder+'/'+self.lis[0]))]\n        \n        img = np.array(Image.open(file_path))\n        img = self.transform(image=img)\n        #img = self.gammaCorrection(img)\n        return {'x': img, 'y':y}","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:08.989669Z","iopub.execute_input":"2023-09-27T14:21:08.990050Z","iopub.status.idle":"2023-09-27T14:21:09.008579Z","shell.execute_reply.started":"2023-09-27T14:21:08.990019Z","shell.execute_reply":"2023-09-27T14:21:09.006963Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"dts = Data('/kaggle/input/dermnet/train',train=True,test=False)\ndval = Data('/kaggle/input/dermnet/train',train=False,test=False)\ndtest=Data('/kaggle/input/dermnet/test',train=False,test=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.011027Z","iopub.execute_input":"2023-09-27T14:21:09.011527Z","iopub.status.idle":"2023-09-27T14:21:09.028385Z","shell.execute_reply.started":"2023-09-27T14:21:09.011480Z","shell.execute_reply":"2023-09-27T14:21:09.027066Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import torchvision\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.029498Z","iopub.execute_input":"2023-09-27T14:21:09.029909Z","iopub.status.idle":"2023-09-27T14:21:09.038414Z","shell.execute_reply.started":"2023-09-27T14:21:09.029877Z","shell.execute_reply":"2023-09-27T14:21:09.037491Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.resnet18(pretrained=True)\nfor param in model.parameters():\n     param.requires_grad = False\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features=num_features, out_features=23)\nfor param in model.fc.parameters():\n    param.requires_grad=True\n# model","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.043079Z","iopub.execute_input":"2023-09-27T14:21:09.043526Z","iopub.status.idle":"2023-09-27T14:21:09.303794Z","shell.execute_reply.started":"2023-09-27T14:21:09.043490Z","shell.execute_reply":"2023-09-27T14:21:09.302500Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=dts,batch_size=32,shuffle=True)\nval_loader = DataLoader(dataset=dval,batch_size=32,shuffle=False)\ntestloader=DataLoader(dataset=dtest,batch_size=32,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.310351Z","iopub.execute_input":"2023-09-27T14:21:09.311256Z","iopub.status.idle":"2023-09-27T14:21:09.318403Z","shell.execute_reply.started":"2023-09-27T14:21:09.311214Z","shell.execute_reply":"2023-09-27T14:21:09.316895Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\n# import torchmetrics.cl\nfrom torchmetrics import F1Score\nfrom torchmetrics.classification import MulticlassF1Score","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.320048Z","iopub.execute_input":"2023-09-27T14:21:09.320501Z","iopub.status.idle":"2023-09-27T14:21:09.332878Z","shell.execute_reply.started":"2023-09-27T14:21:09.320456Z","shell.execute_reply":"2023-09-27T14:21:09.331220Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"f1=MulticlassF1Score(num_classes=23).to(device)\nimport gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.334656Z","iopub.execute_input":"2023-09-27T14:21:09.335056Z","iopub.status.idle":"2023-09-27T14:21:09.783631Z","shell.execute_reply.started":"2023-09-27T14:21:09.335017Z","shell.execute_reply":"2023-09-27T14:21:09.782405Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"1952"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass FocalLoss(nn.modules.loss._WeightedLoss):\n    def __init__(self, weight=None, gamma=4,reduction='mean'):\n        super(FocalLoss, self).__init__(weight,reduction=reduction)\n        self.gamma = gamma\n        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n\n    def forward(self, input, target):\n\n        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n        return focal_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.785487Z","iopub.execute_input":"2023-09-27T14:21:09.785990Z","iopub.status.idle":"2023-09-27T14:21:09.795388Z","shell.execute_reply.started":"2023-09-27T14:21:09.785946Z","shell.execute_reply":"2023-09-27T14:21:09.793938Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"loss_fn = FocalLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ndef epoc(model,epochs=1):\n    \n    for epoch in range(epochs):\n        model.train()\n    #     acc=0\n        loss_train = 0\n        for data in tqdm(train_loader,total = len(train_loader)):\n            torch.cuda.empty_cache()\n            model = model.to(device)\n            for k,v in data.items():\n                if type(v)==dict:\n                    data[k] = v['image'].to(device)\n                else:\n                    data[k]=v.to(device)\n            x = data['x']\n            optimizer.zero_grad()\n            outs = model(x)\n    #         print(data['y'])\n            outs = nn.Softmax(dim=1)(outs)\n\n    #       \n            one_hot =torch.tensor( torch.nn.functional.one_hot(data['y'],23 ),dtype=float)\n            #print(data['y'])\n            loss = loss_fn(outs,one_hot)\n            loss.backward()\n            optimizer.step()\n            outs=outs.argmax(axis=1)\n            loss_train += loss.item()\n            f11=f1(outs,data['y'])\n            print(f11)\n    #         acc=torch.sum(outs==data['y'])/128\n\n    #         print(acc)\n            for k,v in data.items():\n                if type(v)==dict:\n                    data[k] = v['image'].to('cpu')\n                else:\n                    data[k]=v.to('cpu')\n\n    #     print(loss_train/len(train_loader))\n\n    #     print(acc)\n\n    #         l.extend(outs)\n    #         len(l)\n    #         l2.extend(data['y'])\n    #         print(outs.shape,data['y'].shape)\n    # print(len(l))    ","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.797079Z","iopub.execute_input":"2023-09-27T14:21:09.797476Z","iopub.status.idle":"2023-09-27T14:21:09.814737Z","shell.execute_reply.started":"2023-09-27T14:21:09.797443Z","shell.execute_reply":"2023-09-27T14:21:09.813406Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"epoc(model,2)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T14:21:09.816277Z","iopub.execute_input":"2023-09-27T14:21:09.816675Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/326 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60bdbd8b843a44f58ee248a1b2f5314e"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_32/4040144701.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  one_hot =torch.tensor( torch.nn.functional.one_hot(data['y'],23 ),dtype=float)\n","output_type":"stream"},{"name":"stdout","text":"tensor(0.0299)\ntensor(0.0104)\ntensor(0.0078)\ntensor(0.0211)\ntensor(0.0038)\ntensor(0.0132)\ntensor(0.0074)\ntensor(0.0169)\ntensor(0.0074)\ntensor(0.0114)\ntensor(0.0065)\ntensor(0.)\ntensor(0.0114)\ntensor(0.0276)\ntensor(0.0208)\ntensor(0.0069)\ntensor(0.0246)\ntensor(0.0030)\ntensor(0.0051)\ntensor(0.0065)\ntensor(0.0118)\ntensor(0.0090)\ntensor(0.0084)\ntensor(0.0110)\ntensor(0.0333)\ntensor(0.0472)\ntensor(0.0103)\ntensor(0.0592)\ntensor(0.0539)\ntensor(0.0110)\ntensor(0.0101)\ntensor(0.0143)\ntensor(0.0132)\ntensor(0.0159)\ntensor(0.0074)\ntensor(0.0084)\ntensor(0.0069)\ntensor(0.0122)\ntensor(0.0047)\ntensor(0.0143)\ntensor(0.0417)\ntensor(0.0822)\ntensor(0.0422)\ntensor(0.0154)\ntensor(0.)\ntensor(0.0059)\ntensor(0.0278)\ntensor(0.0235)\ntensor(0.0699)\ntensor(0.0625)\ntensor(0.0196)\ntensor(0.0298)\ntensor(0.0631)\ntensor(0.0480)\ntensor(0.0586)\ntensor(0.0611)\ntensor(0.0681)\ntensor(0.0562)\ntensor(0.0492)\ntensor(0.0316)\ntensor(0.0410)\ntensor(0.0440)\ntensor(0.0472)\ntensor(0.0179)\ntensor(0.0301)\ntensor(0.0302)\ntensor(0.0292)\ntensor(0.0242)\ntensor(0.0125)\ntensor(0.0238)\ntensor(0.0198)\ntensor(0.0498)\ntensor(0.0322)\ntensor(0.0293)\ntensor(0.0447)\ntensor(0.0225)\ntensor(0.0263)\ntensor(0.0559)\ntensor(0.0197)\ntensor(0.0125)\ntensor(0.0344)\ntensor(0.0332)\ntensor(0.0196)\ntensor(0.0744)\ntensor(0.0621)\ntensor(0.0701)\ntensor(0.0439)\ntensor(0.0490)\ntensor(0.0940)\ntensor(0.0929)\ntensor(0.0597)\ntensor(0.1090)\ntensor(0.0469)\ntensor(0.0822)\ntensor(0.1192)\ntensor(0.0991)\ntensor(0.1017)\ntensor(0.0148)\ntensor(0.0843)\ntensor(0.0909)\ntensor(0.0574)\ntensor(0.0326)\ntensor(0.0065)\ntensor(0.1118)\ntensor(0.0949)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nl2=torch.empty((0,1), dtype=torch.float32,device=device)\nwith torch.no_grad():\n    for data in tqdm(val_loader,total = len(val_loader)):\n        torch.cuda.empty_cache()\n        model = model.to(device)\n        for k,v in data.items():\n            if type(v)==dict:\n                data[k] = v['image'].to(device)\n            else:\n                data[k]=v.to(device)\n        x = data['x']\n        outs = model(x)\n\n        outs = nn.Softmax(dim=1)(outs)\n        outs=outs.argmax(axis=1)\n        f11=f1(outs,data['y'])\n        outs=outs.view((-1,1))\n        l=torch.cat((l,outs),0)\n        print(f11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    l2=l2\n    print(dfval['y'].shape)\n    print(l2.shape)\n    arr = dfval['y'].to_numpy().reshape(-1,1)\n    f11=f1(l2,torch.tensor(arr,device=device))\n    print(f11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = torch.empty((0,1), dtype=torch.float32,device=device)\nwith torch.no_grad():\n    for data in tqdm(testloader,total = len(testloader)):\n        torch.cuda.empty_cache()\n        model = model.to(device)\n        for k,v in data.items():\n            if type(v)==dict:\n                data[k] = v['image'].to(device)\n            else:-\n                data[k]=v.to(device)\n        x = data['x']\n        outs = model(x)\n\n        outs = nn.Softmax(dim=1)(outs)\n        outs=outs.argmax(axis=1)\n        \n#         \n        f11=f1(outs,data['y'])\n        print(f11)\n        outs=outs.view((-1,1))\n        l=torch.cat((l,outs),0)\n        print(outs.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    l=l\n    print(dftest['y'].shape)\n    print(l.shape)\n    arr = dftest['y'].to_numpy().reshape(-1,1)\n    f11=f1(l,torch.tensor(arr,device=device))\n    print(f11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle \npickle_out = open(\"classifier.pkl\",\"wb\")\npickle.dump(model,pickle_out)\npickle_out.close","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle_out = open(\"classifier.pkl\",\"wb\")\npickle.dump(model,pickle_out)\npickle_out.close","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working/classifier.pkl','classifierpkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}